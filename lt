qus 1



import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.datasets import fetch_california_housing
from sklearn.linear_model import LinearRegression ,Ridge
from sklearn.preprocessing import StandardScaler

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report
from sklearn.metrics import  mean_absolute_error , r2_score
housing=fetch_california_housing()
df=pd.DataFrame(housing.data, columns=housing.feature_names)
df['MEDV']=housing.target
print("Features:")
print(df.head())
print(df.describe())
print("\nMissing values in the dataset:")
print(df.isnull().sum())


X_train,X_test,y_train,y_test=train_test_split(X, y,test_size=0.2,random_state=42)
lin_reg=LinearRegression()
lin_reg.fit(X_train,y_train)
y_pred_lr=lin_reg.predict(X_test)

y_train_log=np.log(y_train)
y_test_log=np.log(y_test)
scaler=StandardScaler
X_train_scaled=scaler_fit_transform(X_train)



iris = load_iris()
df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
df['species'] = iris.target


print(f"Number : {df.shape[1] - 1}")


plt.figure(figsize=(10, 6))
sns.boxplot(data=df.iloc[:, :-1])
plt.title('Boxplot')
plt.show()


species_counts = df['species'].value_counts()
species_counts.plot(kind='bar', color=['blue', 'orange', 'green'])
plt.title('Standard Scalar')
plt.xlabel('Regression')
plt.ylabel('RMSE')
plt.show()


X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df['species'], test_size=0.3, random_state=42)


knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)
knn_pred = knn.predict(X_test)


svm = SVC(kernel='linear')
svm.fit(X_train, y_train)
svm_pred = svm.predict(X_test)


print("Standard Scalar:")
print(f"Accuracy: {accuracy_score(y_test, knn_pred)}")
print(classification_report(y_test, knn_pred))

print("Accuracy:")
print(f"Accuracy: {accuracy_score(y_test, svm_pred)}")
print(classification_report(y_test, svm_pred))

results = []

for k in [3, 5, 7]:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    knn_pred = knn.predict(X_test)
    results.append({'Model': 'k-NN', 'R-squared': k, 'Accuracy': accuracy_score(y_test, knn_pred)})

for c in [0.1, 1, 10]:
    svm = SVC(kernel='linear', C=c)
    svm.fit(X_train, y_train)
    svm_pred = svm.predict(X_test)
    results.append({'Model': 'SVM', 'Ridge Regression': c, 'Accuracy': accuracy_score(y_test, svm_pred)})

results_df = pd.DataFrame(results)
print(results_df)


qus 2

import numpy as np

def reverse_if_anagram(arr):
    # Dictionary to store sorted versions of strings and their indices
    anagram_groups = {}
    
    # Populate the dictionary with sorted strings as keys and list of indices as values
    for i, s in enumerate(arr):
        sorted_s = ''.join(sorted(s))
        if sorted_s in anagram_groups:
            anagram_groups[sorted_s].append(i)
        else:
            anagram_groups[sorted_s] = [i]
    
    # Reverse strings that have at least one anagram
    for indices in anagram_groups.values():
        if len(indices) > 1: # Only if there are anagrams (more than one index for the sorted string)
            for i in indices:
                arr[i] = arr[i][::-1] # Reverse the string
    
    return arr

# Test the function
test_array = np.array(["listen", "silent", "enlist", "hello", "world"])
print("Original Array:", test_array)
print("Modified Array:", reverse_if_anagram(test_array))
